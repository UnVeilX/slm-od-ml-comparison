{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Image object-detection using MMDetection specific pipeline component\n",
        "\n",
        "This sample shows how to use `mmdetection_image_objectdetection_instancesegmentation_pipeline` component from the `azureml` system registry to fine tune a model for image object-detection task using fridgeObjects Dataset. We then deploy the fine tuned model to an online endpoint for real time inference.\n",
        "\n",
        "### Training data\n",
        "We will use the [surfacelandmines](https://github.com/UnVeilX/slm-od-ml-comparison/tree/main/datasets) dataset.\n",
        "\n",
        "### Model\n",
        "We will use the `vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco` model in this notebook. If you need to fine tune a model that is available on MMDetection model zoo, but not available in `azureml` system registry, you can either register the model and use the registered model or use the `model_name` parameter to instruct the components to pull the model directly from MMDetection model zoo.\n",
        "\n",
        "### Outline\n",
        "1. Install dependencies\n",
        "2. Setup pre-requisites such as compute\n",
        "3. Pick a model to fine tune\n",
        "4. Prepare dataset for finetuning the model\n",
        "5. Submit the fine tuning job using MMDetection specific image object-detection and instance-segmentation component\n",
        "6. Review training and evaluation metrics\n",
        "7. Register the fine tuned model\n",
        "8. Deploy the fine tuned model for real time inference\n",
        "9. Test deployed end point\n",
        "9. Clean up resources"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 1. Install dependencies\n",
        "Before starting off, if you are running the notebook on Azure Machine Learning Studio or running first time locally, you will need the following packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install azure-ai-ml==1.8.0\n",
        "! pip install azure-identity==1.13.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-ml==1.8.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.8.0)\nRequirement already satisfied: colorama<0.5.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (0.4.6)\nRequirement already satisfied: azure-storage-file-datalake<13.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (12.16.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (1.30.1)\nRequirement already satisfied: tqdm<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (4.66.2)\nRequirement already satisfied: pydash<6.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (5.1.2)\nRequirement already satisfied: azure-common<2.0.0,>=1.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (1.1.28)\nRequirement already satisfied: strictyaml<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (1.7.3)\nRequirement already satisfied: azure-storage-file-share<13.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (12.17.0)\nRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (0.7.1)\nRequirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (2.4.0)\nRequirement already satisfied: typing-extensions<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (4.12.2)\nRequirement already satisfied: opencensus-ext-azure<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (1.1.13)\nRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (6.0.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (3.21.3)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (4.21.1)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (12.21.0)\nRequirement already satisfied: isodate in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (0.6.1)\nRequirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-ai-ml==1.8.0) (1.4.0)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (1.16.0)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (2.31.0)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.8.0) (38.0.4)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.8.0) (0.35.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.8.0) (2023.12.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.8.0) (23.2.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.8.0) (0.18.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml==1.8.0) (24.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from msrest>=0.6.18->azure-ai-ml==1.8.0) (2022.9.24)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from msrest>=0.6.18->azure-ai-ml==1.8.0) (2.0.0)\nRequirement already satisfied: psutil>=5.6.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (5.9.3)\nRequirement already satisfied: opencensus<1.0.0,>=0.11.4 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (0.11.4)\nRequirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (1.13.0)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from strictyaml<2.0.0->azure-ai-ml==1.8.0) (2.9.0.post0)\nRequirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (1.0.0)\nRequirement already satisfied: msal<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (1.27.0)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.8.0) (1.16.0)\nRequirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (2.18.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (1.26.18)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml==1.8.0) (3.2.2)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.8.0) (2.22)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (1.63.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (3.20.3)\nRequirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (2.29.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (1.23.0)\nRequirement already satisfied: portalocker<3,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (2.8.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (4.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (5.3.3)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (0.4.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (0.6.0)\nRequirement already satisfied: azure-identity==1.13.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.13.0)\nRequirement already satisfied: cryptography>=2.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-identity==1.13.0) (38.0.4)\nRequirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-identity==1.13.0) (1.0.0)\nRequirement already satisfied: msal<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-identity==1.13.0) (1.27.0)\nRequirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-identity==1.13.0) (1.16.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-identity==1.13.0) (1.30.1)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (2.31.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (4.12.2)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from cryptography>=2.5->azure-identity==1.13.0) (1.16.0)\nRequirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from msal<2.0.0,>=1.20.0->azure-identity==1.13.0) (2.4.0)\nRequirement already satisfied: portalocker<3,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity==1.13.0) (2.8.2)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity==1.13.0) (2.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (3.3.2)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (2022.9.24)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (1.26.18)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (3.7)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 2. Setup pre-requisites"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Connect to Azure Machine Learning workspace\n",
        "\n",
        "Before we dive in the code, you'll need to connect to your workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
        "\n",
        "We are using `DefaultAzureCredential` to get access to workspace. `DefaultAzureCredential` should be capable of handling most scenarios. If you want to learn more about other available credentials, go to [set up authentication doc](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk), [azure-identity reference doc](https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python).\n",
        "\n",
        "Replace `<AML_WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` with their respective values in the below cell."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "\n",
        "experiment_name = (\n",
        "    \"AzureML-Train-Finetune-Vision-OD-UVXDataset12-2_5-Algo4-rs\"  # can rename to any valid name\n",
        ")\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "workspace_ml_client = None\n",
        "try:\n",
        "    workspace_ml_client = MLClient.from_config(credential)\n",
        "    subscription_id = workspace_ml_client.subscription_id\n",
        "    resource_group = workspace_ml_client.resource_group_name\n",
        "    workspace_name = workspace_ml_client.workspace_name\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    # Enter details of your AML workspace\n",
        "    subscription_id = \"fdb5d841-c563-47cd-9530-53dbd266c1fb\"\n",
        "    resource_group = \"rg-unveilx\"\n",
        "    workspace_name = \"ml-landlmine\"\n",
        "\n",
        "workspace_ml_client = MLClient(\n",
        "    credential, subscription_id, resource_group, workspace_name\n",
        ")\n",
        "registry_ml_client = MLClient(\n",
        "    credential,\n",
        "    subscription_id,\n",
        "    resource_group,\n",
        "    registry_name=\"azureml\",\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1725378410610
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Create compute\n",
        "\n",
        "In order to finetune a model on Azure Machine Learning studio, you will need to create a compute resource first. **Creating a compute will take 3-4 minutes.** \n",
        "\n",
        "For additional references, see [Azure Machine Learning in a Day](https://github.com/Azure/azureml-examples/blob/main/tutorials/azureml-in-a-day/azureml-in-a-day.ipynb). "
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "##### Create CPU compute for model selection component"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "from azure.core.exceptions import ResourceNotFoundError\n",
        "\n",
        "model_import_cluster_name = \"ldm-cpu-cluster\"\n",
        "try:\n",
        "    _ = workspace_ml_client.compute.get(model_import_cluster_name)\n",
        "    print(\"Found existing compute target.\")\n",
        "except ResourceNotFoundError:\n",
        "    print(\"Creating a new compute target...\")\n",
        "    compute_config = AmlCompute(\n",
        "        name=model_import_cluster_name,\n",
        "        type=\"amlcompute\",\n",
        "        size=\"Standard_E4ds_v4\",\n",
        "        idle_time_before_scale_down=120,\n",
        "        min_instances=0,\n",
        "        max_instances=4,\n",
        "    )\n",
        "    workspace_ml_client.begin_create_or_update(compute_config).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1725378414248
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "##### Create GPU compute for finetune component\n",
        "\n",
        "The list of GPU machines can be found [here](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_cluster_name = \"aml-cv-bg-cl\"\n",
        "\n",
        "try:\n",
        "    _ = workspace_ml_client.compute.get(finetune_cluster_name)\n",
        "    print(\"Found existing compute target.\")\n",
        "except ResourceNotFoundError:\n",
        "    print(\"Creating a new compute target...\")\n",
        "    compute_config = AmlCompute(\n",
        "        name=finetune_cluster_name,\n",
        "        type=\"amlcompute\",\n",
        "        size=\"Standard_ND40rs_v2\",\n",
        "        idle_time_before_scale_down=120,\n",
        "        min_instances=0,\n",
        "        max_instances=4,\n",
        "    )\n",
        "    workspace_ml_client.begin_create_or_update(compute_config).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1725378418746
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create GPU compute for model evaluation component\n",
        "\n",
        "The list of GPU machines can be found [here](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import warnings\n",
        "\n",
        "# Using the same compute cluster for model evaluation as finetuning. If you want to use a different cluster, specify it below\n",
        "model_eval_cluster_name = \"cl-aml-cv-lmd\"\n",
        "\n",
        "try:\n",
        "    model_evaluation_compute = workspace_ml_client.compute.get(model_eval_cluster_name)\n",
        "    print(\"Found existing compute target.\")\n",
        "except ResourceNotFoundError:\n",
        "    print(\"Creating a new compute target...\")\n",
        "    model_evaluation_compute = AmlCompute(\n",
        "        name=model_eval_cluster_name,\n",
        "        type=\"amlcompute\",\n",
        "        size=\"Standard_NC6s_v3\",\n",
        "        idle_time_before_scale_down=120,\n",
        "        min_instances=0,\n",
        "        max_instances=4,\n",
        "    )\n",
        "    workspace_ml_client.begin_create_or_update(compute_config).result()\n",
        "\n",
        "model_evaluation_compute_instance_type = model_evaluation_compute.size\n",
        "print(\n",
        "    f\"Model Evaluation compute's instance type: {model_evaluation_compute_instance_type}\"\n",
        ")\n",
        "\n",
        "if model_evaluation_compute_instance_type != \"STANDARD_NC6S_V3\":\n",
        "    # Print a warning message if compute type is not 'STANDARD_NC6S_V3', i.e. Single GPU V100\n",
        "    warning_message = (\n",
        "        \"Warning! Currently evaluation is only supported on STANDARD_NC6S_V3 compute type.\"\n",
        "        \" Please change the compute type to STANDARD_NC6S_V3 if you want to run evaluation.\"\n",
        "    )\n",
        "    warnings.warn(warning_message, category=Warning)\n",
        "# generating a unique timestamp that can be used for names and versions that need to be unique\n",
        "timestamp = str(int(time.time()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target.\nModel Evaluation compute's instance type: STANDARD_NC6S_V3\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1725378423828
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Pick a foundation model to fine tune\n",
        "\n",
        "We will use the `vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco` model in this notebook. If you need to fine tune a model that is available on MMDetection model zoo, but not available in `azureml` system registry, you can either register the model and use the registered model or use the `model_name` parameter to instruct the components to pull the model directly from MMDetection model zoo.\n",
        "\n",
        "Currently following models are supported:\n",
        "\n",
        "| Model Name | Source |\n",
        "| :------------: | :-------:  |\n",
        "| [mmd-3x-deformable-detr_refine_twostage_r50_16xb2-50e_coco](https://ml.azure.com/registries/azureml/models/mmd-3x-deformable-detr_refine_twostage_r50_16xb2-50e_coco/version/12) | azureml registry |\n",
        "| [mmd-3x-sparse-rcnn_r50_fpn_300-proposals_crop-ms-480-800-3x_coco](https://ml.azure.com/registries/azureml/models/mmd-3x-sparse-rcnn_r50_fpn_300-proposals_crop-ms-480-800-3x_coco/version/12) | azureml registry |\n",
        "| [mmd-3x-sparse-rcnn_r101_fpn_300-proposals_crop-ms-480-800-3x_coco](https://ml.azure.com/registries/azureml/models/mmd-3x-sparse-rcnn_r101_fpn_300-proposals_crop-ms-480-800-3x_coco/version/12) | azureml registry |\n",
        "| [mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco](https://ml.azure.com/registries/azureml/models/mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco/version/12) | azureml registry |\n",
        "| [mmd-3x-vfnet_x101-64x4d-mdconv-c3-c5_fpn_ms-2x_coco](https://ml.azure.com/registries/azureml/models/mmd-3x-vfnet_x101-64x4d-mdconv-c3-c5_fpn_ms-2x_coco/version/12) | azureml registry |\n",
        "| [mmd-3x-yolof_r50_c5_8x8_1x_coco](https://ml.azure.com/registries/azureml/models/mmd-3x-yolof_r50_c5_8x8_1x_coco/version/12) | azureml registry |\n",
        "| [Image object detection models from MMDetection](https://github.com/open-mmlab/mmdetection/blob/v3.1.0/docs/en/model_zoo.md) | MMDetection |"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mmdetection_model_name = \"vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco\"\n",
        "\n",
        "aml_registry_model_name = \"mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco\"\n",
        "foundation_models = registry_ml_client.models.list(name=aml_registry_model_name)\n",
        "foundation_model = max(foundation_models, key=lambda x: int(x.version))\n",
        "print(\n",
        "    f\"\\n\\nUsing model name: {foundation_model.name}, version: {foundation_model.version}, id: {foundation_model.id} for inferencing\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\nUsing model name: mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco, version: 12, id: azureml://registries/azureml/models/mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco/versions/12 for inferencing\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1725378429192
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 4. Prepare the dataset for fine-tuning the model\n",
        "\n",
        "We will use the [surfacelandmines](https://github.com/UnVeilX/slm-od-ml-comparison/tree/main/datasets), a dataset called Surface Landmines Objects, which consists of 78 images of 1 label of  {`landmine`} photos taken on different backgrounds.\n",
        "\n",
        "\n",
        "#### 4.1 Download the Data and upload to Azure Machine Learning Studio Data Labeling"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2 Point to MLTable data input"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_mltable_path = \"azureml://subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourcegroups/rg-unveilx/workspaces/ml-landmine/datastores/workspaceblobstore/paths/Labeling/export/export/dataset/656afd06-d1fc-48de-8560-dc6a64ce70c7/b52effb8-b922-4307-82f1-c75babbd0a69/\"\n",
        "validation_mltable_path = \"azureml://subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourcegroups/rg-unveilx/workspaces/ml-landmine/datastores/workspaceblobstore/paths/Labeling/export/export/dataset/058b1b9b-5f92-4033-8077-65e99d78f3b7/d58fdd7e-58e9-414c-98a3-8f34d1764587/\""
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1725378446659
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 5. Submit the fine tuning job using `mmdetection_image_objectdetection_instancesegmentation_pipeline` component\n",
        " \n",
        "Create the job that uses the `mmdetection_image_objectdetection_instancesegmentation_pipeline` component for image object detection and instance segmentation tasks. Learn more in 5.2 about all the parameters supported for fine tuning."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### 5.1 Create component"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "FINETUNE_PIPELINE_COMPONENT_NAME = (\n",
        "    \"mmdetection_image_objectdetection_instancesegmentation_pipeline\"\n",
        ")\n",
        "pipeline_component_mmdetection_func = registry_ml_client.components.get(\n",
        "    name=FINETUNE_PIPELINE_COMPONENT_NAME, label=\"latest\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1725378449016
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Create arguments to be passed to `mmdetection_image_objectdetection_instancesegmentation_pipeline` component\n",
        "\n",
        "The `mmdetection_image_objectdetection_instancesegmentation_pipeline` component consists of model selection and finetuning components. The detailed arguments for each component can be found at following README files:\n",
        "- [Model Import Component](../../docs/component_docs/image_finetune/mmd_model_import_component.md)\n",
        "- [Finetune Component](../../docs/component_docs/image_finetune/mmd_finetune_component.md)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "deepspeed_config_path = \"./deepspeed_configs/zero1.json\"\n",
        "if not os.path.exists(deepspeed_config_path):\n",
        "    print(\"DeepSpeed config file not found\")\n",
        "    deepspeed_config_path = None\n",
        "\n",
        "pipeline_component_args = {\n",
        "    # # Model import args\n",
        "    \"model_family\": \"MmDetectionImage\",\n",
        "    \"download_from_source\": False,  # True for downloading a model directly from MMDetection\n",
        "    \"mlflow_model\": foundation_model.id,  # foundation_model.id is provided, only foundation_model gives UserErrorException: only path input is supported now but get: ...\n",
        "    # \"model_name\": mmdetection_model_name, # specify the model_name instead of mlflow_model if you want to use a model from the mmdetection model zoo\n",
        "    # Finetune args\n",
        "    \"task_name\": \"image-object-detection\",\n",
        "    \"apply_augmentations\": True,\n",
        "    \"number_of_workers\": 8,\n",
        "    \"apply_deepspeed\": False,\n",
        "    \"deepspeed_config\": deepspeed_config_path,\n",
        "    \"apply_ort\": False,\n",
        "    \"auto_find_batch_size\": False,\n",
        "    \"extra_optim_args\": \"\",\n",
        "    \"precision\": \"32\",\n",
        "    \"random_seed\": 42,\n",
        "    \"evaluation_strategy\": \"epoch\",\n",
        "    \"evaluation_steps\": 500,\n",
        "    \"logging_strategy\": \"epoch\",\n",
        "    \"logging_steps\": 500,\n",
        "    \"save_strategy\": \"epoch\",\n",
        "    \"save_steps\": 500,\n",
        "    \"save_total_limit\": -1,\n",
        "    \"early_stopping\": False,\n",
        "    \"early_stopping_patience\": 1,\n",
        "    \"resume_from_checkpoint\": False,\n",
        "    \"save_as_mlflow_model\": True,\n",
        "    # # Uncomment one or more lines below to provide specific values, if you wish you override the autoselected default values.\n",
        "    # \"image_min_size\": -1,\n",
        "    # \"image_max_size\": -1,\n",
        "    # \"metric_for_best_model\": \"mean_average_precision\",\n",
        "    # \"number_of_epochs\": 15,\n",
        "    # \"max_steps\": -1,\n",
        "    # \"training_batch_size\": 4,\n",
        "    # \"validation_batch_size\": 4,\n",
        "    # \"learning_rate\": 5e-5,\n",
        "    # \"learning_rate_scheduler\": \"warmup_linear\",\n",
        "    # \"warmup_steps\": 0,\n",
        "    # \"optimizer\": \"adamw_hf\",\n",
        "    # \"weight_decay\": 0.0,\n",
        "    # \"gradient_accumulation_step\": 1,\n",
        "    # \"max_grad_norm\": 1.0,\n",
        "    # \"iou_threshold\": 0.5,\n",
        "    # \"box_score_threshold\": 0.3,\n",
        "    # # Model evaluation args\n",
        "    # The following parameters map to the dataset fields\n",
        "    # Uncomment one or more lines below to provide specific values, if you wish you override the autoselected default values.\n",
        "    # \"label_column_name\": \"label\",\n",
        "    # \"input_column_names\": \"image_url\",\n",
        "}\n",
        "instance_count = 1\n",
        "process_count_per_instance = 1\n",
        "\n",
        "# Ensure that the user provides only one of mlflow_model or model_name\n",
        "if (\n",
        "    pipeline_component_args.get(\"mlflow_model\") is None\n",
        "    and pipeline_component_args.get(\"model_name\") is None\n",
        "):\n",
        "    raise ValueError(\n",
        "        \"You must specify either mlflow_model or model_name for the model to finetune\"\n",
        "    )\n",
        "if (\n",
        "    pipeline_component_args.get(\"mlflow_model\") is not None\n",
        "    and pipeline_component_args.get(\"model_name\") is not None\n",
        "):\n",
        "    raise ValueError(\n",
        "        \"You must specify ONLY one of mlflow_model and model_name for the model to finetune\"\n",
        "    )\n",
        "elif (\n",
        "    pipeline_component_args.get(\"mlflow_model\") is None\n",
        "    and pipeline_component_args.get(\"model_name\") is not None\n",
        "):\n",
        "    use_model_name = mmdetection_model_name\n",
        "elif (\n",
        "    pipeline_component_args.get(\"mlflow_model\") is not None\n",
        "    and pipeline_component_args.get(\"model_name\") is None\n",
        "):\n",
        "    use_model_name = aml_registry_model_name\n",
        "print(f\"Finetuning model {use_model_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Finetuning model mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1725378468218
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### 5.3 Utility function to create pipeline using `mmdetection_image_objectdetection_instancesegmentation_pipeline` component"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml.entities import PipelineComponent\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "\n",
        "@pipeline()\n",
        "def create_pipeline_mmdetection():\n",
        "    \"\"\"Create pipeline.\"\"\"\n",
        "\n",
        "    mmdetection_pipeline_component: PipelineComponent = pipeline_component_mmdetection_func(\n",
        "        compute_model_import=model_import_cluster_name,\n",
        "        compute_finetune=finetune_cluster_name,\n",
        "        compute_model_evaluation=model_eval_cluster_name,\n",
        "        training_data=Input(type=AssetTypes.MLTABLE, path=training_mltable_path),\n",
        "        validation_data=Input(type=AssetTypes.MLTABLE, path=validation_mltable_path),\n",
        "        # test data\n",
        "        # Using the same data for validation and test. If you want to use a different dataset for test, specify it below\n",
        "        test_data=Input(type=AssetTypes.MLTABLE, path=validation_mltable_path),\n",
        "        instance_count=instance_count,\n",
        "        process_count_per_instance=process_count_per_instance,\n",
        "        **pipeline_component_args,\n",
        "    )\n",
        "    return {\n",
        "        # Map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model. Registering the model is required to deploy the model to an online or batch endpoint.\n",
        "        \"trained_model\": mmdetection_pipeline_component.outputs.mlflow_model_folder,\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1725378472556
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### 5.4 Run the fine tuning job using `mmdetection_image_objectdetection_instancesegmentation_pipeline` component"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mmdetection_pipeline_object = create_pipeline_mmdetection()\n",
        "\n",
        "# don't use cached results from previous jobs\n",
        "mmdetection_pipeline_object.settings.force_rerun = True\n",
        "\n",
        "# set continue on step failure to False\n",
        "mmdetection_pipeline_object.settings.continue_on_step_failure = False\n",
        "\n",
        "mmdetection_pipeline_object.display_name = (\n",
        "    use_model_name + \"_mmdetection_pipeline_component_run_\" + \"od\"\n",
        ")\n",
        "# Don't use cached results from previous jobs\n",
        "mmdetection_pipeline_object.settings.force_rerun = True\n",
        "\n",
        "print(\"Submitting pipeline\")\n",
        "\n",
        "mmdetection_pipeline_run = workspace_ml_client.jobs.create_or_update(\n",
        "    mmdetection_pipeline_object, experiment_name=experiment_name\n",
        ")\n",
        "\n",
        "print(f\"Pipeline created. URL: {mmdetection_pipeline_run.studio_url}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting pipeline\nPipeline created. URL: https://ml.azure.com/runs/brave_hair_2pv87m0kt1?wsid=/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourcegroups/rg-unveilx/workspaces/ml-landmine&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1725379263317
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workspace_ml_client.jobs.stream(mmdetection_pipeline_run.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: brave_hair_2pv87m0kt1\nWeb View: https://ml.azure.com/runs/brave_hair_2pv87m0kt1?wsid=/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourcegroups/rg-unveilx/workspaces/ml-landmine\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-09-03 16:01:05Z] Submitting 1 runs, first five are: c9a7c039:64f9a4d0-8467-43e6-9ef9-f443039ddca7\n[2024-09-03 17:01:32Z] Completing processing run id 64f9a4d0-8467-43e6-9ef9-f443039ddca7.\n\nExecution Summary\n=================\nRunId: brave_hair_2pv87m0kt1\nWeb View: https://ml.azure.com/runs/brave_hair_2pv87m0kt1?wsid=/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourcegroups/rg-unveilx/workspaces/ml-landmine\n\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1725382923841
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 6. Get metrics from finetune component\n",
        "\n",
        "The model training happens as part of the finetune component. Please follow below steps to extract validation metrics from the run."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "##### 6.1 Initialize MLFlow Client\n",
        "\n",
        "The models and artifacts that are produced by AutoML can be accessed via the MLFlow interface.\n",
        "Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\n",
        "\n",
        "IMPORTANT - You need to have installed the latest MLFlow packages with:\n",
        "\n",
        "    pip install azureml-mlflow\n",
        "    pip install mlflow"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "# Obtain the tracking URL from MLClient\n",
        "MLFLOW_TRACKING_URI = workspace_ml_client.workspaces.get(\n",
        "    name=workspace_ml_client.workspace_name\n",
        ").mlflow_tracking_uri\n",
        "\n",
        "print(MLFLOW_TRACKING_URI)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml://westus2.api.azureml.ms/mlflow/v1.0/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourceGroups/rg-unveilx/providers/Microsoft.MachineLearningServices/workspaces/ml-landmine\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1725386721753
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the MLFLOW TRACKING URI\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "print(f\"\\nCurrent tracking uri: {mlflow.get_tracking_uri()}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent tracking uri: azureml://westus2.api.azureml.ms/mlflow/v1.0/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourceGroups/rg-unveilx/providers/Microsoft.MachineLearningServices/workspaces/ml-landmine\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1725386724066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.tracking.client import MlflowClient\n",
        "\n",
        "# Initialize MLFlow client\n",
        "mlflow_client = MlflowClient()"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1725386727917
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### 6.2 Get the training and evaluation run\n",
        "\n",
        "Fetch the training and evaluation run ids from the above pipeline run. We will later use these run ids to fetch the metrics. We will use the training run id to register the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Concat 'tags.mlflow.rootRunId=' and pipeline_job.name in single quotes as filter variable\n",
        "filter = \"tags.mlflow.rootRunId='\" + mmdetection_pipeline_run.name + \"'\"\n",
        "runs = mlflow.search_runs(\n",
        "    experiment_names=[experiment_name], filter_string=filter, output_format=\"list\"\n",
        ")\n",
        "\n",
        "# Get the training and evaluation runs.\n",
        "# Using a hacky way till 'Bug 2320997: not able to show eval metrics in FT notebooks - mlflow client now showing display names' is fixed\n",
        "for run in runs:\n",
        "    # Check if run.data.metrics.epoch exists\n",
        "    if \"epoch\" in run.data.metrics:\n",
        "        training_run = run\n",
        "    # Else, check if run.data.metrics.accuracy exists\n",
        "    elif \"mean_average_precision\" in run.data.metrics:\n",
        "        evaluation_run = run"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1725386855107
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### 6.3 Get training metrics\n",
        "\n",
        "Access the results (such as Models, Artifacts, Metrics) of a previously completed run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(training_run.data.metrics, index=[0]).T"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "                                   0\nloss                        1.025700\ngrad_norm                   4.454677\nlearning_rate               0.000000\nepoch                      15.000000\nprecision                   1.000000\nrecall                      1.000000\nmean_average_precision      1.000000\nruntime                     2.809600\nsamples_per_second          6.051000\nsteps_per_second            1.780000\ncheckpoint_save_step      285.000000\nruntime_train             376.818900\nsamples_per_second_train    3.025000\nsteps_per_second_train      0.756000\ntotal_flos                  0.000000\nloss_train                  5.820303",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>loss</th>\n      <td>1.025700</td>\n    </tr>\n    <tr>\n      <th>grad_norm</th>\n      <td>4.454677</td>\n    </tr>\n    <tr>\n      <th>learning_rate</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>precision</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>mean_average_precision</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>runtime</th>\n      <td>2.809600</td>\n    </tr>\n    <tr>\n      <th>samples_per_second</th>\n      <td>6.051000</td>\n    </tr>\n    <tr>\n      <th>steps_per_second</th>\n      <td>1.780000</td>\n    </tr>\n    <tr>\n      <th>checkpoint_save_step</th>\n      <td>285.000000</td>\n    </tr>\n    <tr>\n      <th>runtime_train</th>\n      <td>376.818900</td>\n    </tr>\n    <tr>\n      <th>samples_per_second_train</th>\n      <td>3.025000</td>\n    </tr>\n    <tr>\n      <th>steps_per_second_train</th>\n      <td>0.756000</td>\n    </tr>\n    <tr>\n      <th>total_flos</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>loss_train</th>\n      <td>5.820303</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1725386855401
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 7. Register the fine tuned model with the workspace\n",
        "\n",
        "We will register the model from the output of the fine tuning job. This will track lineage between the fine tuned model and the fine tuning job. The fine tuning job, further, tracks lineage to the foundation model, data and training code."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Generating a unique timestamp that can be used for names and versions that need to be unique\n",
        "timestamp = str(int(time.time()))"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1725386855640
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# Check if the `trained_model` output is available\n",
        "print(\n",
        "    f\"Pipeline job outputs: {workspace_ml_client.jobs.get(mmdetection_pipeline_run.name).outputs}\"\n",
        ")\n",
        "\n",
        "# Fetch the model from pipeline job output - not working, hence fetching from fine tune child job\n",
        "model_path_from_job = (\n",
        "    f\"azureml://jobs/{mmdetection_pipeline_run.name}/outputs/trained_model\"\n",
        ")\n",
        "print(f\"Path to register model: {model_path_from_job}\")\n",
        "\n",
        "finetuned_model_name = f\"{use_model_name.replace('/', '-')}-landmine-objects-od\"\n",
        "finetuned_model_description = f\"{use_model_name.replace('/', '-')} fine tuned model for fridge objects object detection\"\n",
        "prepare_to_register_model = Model(\n",
        "    path=model_path_from_job,\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    name=finetuned_model_name,\n",
        "    version=timestamp,  # Use timestamp as version to avoid version conflict\n",
        "    description=finetuned_model_description,\n",
        ")\n",
        "print(f\"Prepare to register model: \\n{prepare_to_register_model}\")\n",
        "\n",
        "# Register the model from pipeline job output\n",
        "registered_model = workspace_ml_client.models.create_or_update(\n",
        "    prepare_to_register_model\n",
        ")\n",
        "print(f\"Registered model: {registered_model}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline job outputs: {'trained_model': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x7fccce811580>}\nPath to register model: azureml://jobs/brave_hair_2pv87m0kt1/outputs/trained_model\nPrepare to register model: \ndescription: mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco fine tuned model for fridge\n  objects object detection\nname: mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco-landmine-objects-od\npath: azureml://jobs/brave_hair_2pv87m0kt1/outputs/trained_model\nproperties: {}\ntags: {}\ntype: mlflow_model\nversion: '1725386855'\n\nRegistered model: creation_context:\n  created_at: '2024-09-03T18:08:06.292194+00:00'\n  created_by: Rashid Moin\n  created_by_type: User\n  last_modified_at: '2024-09-03T18:08:06.292194+00:00'\n  last_modified_by: Rashid Moin\n  last_modified_by_type: User\ndescription: mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco fine tuned model for fridge\n  objects object detection\nflavors:\n  python_function:\n    artifacts: \"{\\n  \\\"augmentations_path\\\": {\\n    \\\"path\\\": \\\"artifacts/augmentations.yaml\\\"\\\n      ,\\n    \\\"uri\\\": \\\"output/augmentations.yaml\\\"\\n  },\\n  \\\"config_path\\\": {\\n\\\n      \\    \\\"path\\\": \\\"artifacts/vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco.py\\\",\\n   \\\n      \\ \\\"uri\\\": \\\"output/vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco.py\\\"\\n  },\\n  \\\"model_defaults_path\\\"\\\n      : {\\n    \\\"path\\\": \\\"artifacts/model_defaults.json\\\",\\n    \\\"uri\\\": \\\"output/model_defaults.json\\\"\\\n      \\n  },\\n  \\\"model_metadata\\\": {\\n    \\\"path\\\": \\\"artifacts/model_metadata.json\\\"\\\n      ,\\n    \\\"uri\\\": \\\"output/model_metadata.json\\\"\\n  },\\n  \\\"weights_path\\\": {\\n\\\n      \\    \\\"path\\\": \\\"artifacts/pytorch_model.bin\\\",\\n    \\\"uri\\\": \\\"output/pytorch_model.bin\\\"\\\n      \\n  }\\n}\"\n    cloudpickle_version: 2.2.1\n    code: code\n    env: \"{\\n  \\\"conda\\\": \\\"conda.yaml\\\",\\n  \\\"virtualenv\\\": \\\"python_env.yaml\\\"\\n\\\n      }\"\n    loader_module: mlflow.pyfunc.model\n    python_model: python_model.pkl\n    python_version: 3.10.14\n    streamable: 'false'\nid: azureml:/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourceGroups/rg-unveilx/providers/Microsoft.MachineLearningServices/workspaces/ml-landmine/models/mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco-landmine-objects-od/versions/1725386855\njob_name: brave_hair_2pv87m0kt1\nname: mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco-landmine-objects-od\npath: azureml://subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourceGroups/rg-unveilx/workspaces/ml-landmine/datastores/workspaceblobstore/paths/azureml/c97531a2-4c56-4256-9f21-d9cd6195bab7/mlflow_model_folder/\nproperties: {}\nstage: Development\ntags: {}\ntype: mlflow_model\nversion: '1725386855'\n\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1725386887131
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 8. Deploy the fine tuned model to an online endpoint\n",
        "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
        "\n",
        "# Endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
        "online_endpoint_name = \"mmd-od-landmine-\" + datetime.datetime.now().strftime(\n",
        "    \"%m%d%H%M\"\n",
        ")\n",
        "online_endpoint_description = f\"Online endpoint for {registered_model.name}, finetuned for fridge objects object detection\"\n",
        "# Create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=online_endpoint_description,\n",
        "    auth_mode=\"key\",\n",
        "    tags={\"foo\": \"bar\"},\n",
        ")\n",
        "workspace_ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://mmd-od-landmine-09031808.westus2.inference.ml.azure.com/score', 'openapi_uri': 'https://mmd-od-landmine-09031808.westus2.inference.ml.azure.com/swagger.json', 'name': 'mmd-od-landmine-09031808', 'description': 'Online endpoint for mmd-3x-vfnet_r50-mdconv-c3-c5_fpn_ms-2x_coco-landmine-objects-od, finetuned for fridge objects object detection', 'tags': {'foo': 'bar'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourcegroups/rg-unveilx/providers/microsoft.machinelearningservices/workspaces/ml-landmine/onlineendpoints/mmd-od-landmine-09031808', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/providers/Microsoft.MachineLearningServices/locations/westus2/mfeOperationsStatus/oeidp:6f24ffb1-eb7e-4256-a866-c2b2ef9ef080:7c8964dc-6f62-4f7d-80dc-f0137ef3f530?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/fdb5d841-c563-47cd-9530-53dbd266c1fb/resourceGroups/rg-unveilx/providers/Microsoft.MachineLearningServices/workspaces/ml-landmine/onlineEndpoints/mmd-od-landmine-09031808', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ramoin1/code/Users/ramoin/azureml-examples/sdk/python/foundation-models/system/finetune/image-object-detection', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fcd0b87f070>, 'auth_mode': 'key', 'location': 'westus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fcd0b87f7c0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1725386950693
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import OnlineRequestSettings, ProbeSettings\n",
        "\n",
        "deployment_name = \"mmd-od-landmine-mlflow-deploy\"\n",
        "print(registered_model.id)\n",
        "print(online_endpoint_name)\n",
        "print(deployment_name)\n",
        "\n",
        "# Create a deployment\n",
        "demo_deployment = ManagedOnlineDeployment(\n",
        "    name=deployment_name,\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=registered_model.id,\n",
        "    instance_type=\"Standard_DS3_V2\",\n",
        "    instance_count=1,\n",
        "    request_settings=OnlineRequestSettings(\n",
        "        max_concurrent_requests_per_instance=1,\n",
        "        request_timeout_ms=90000,\n",
        "        max_queue_wait_ms=500,\n",
        "    ),\n",
        "    liveness_probe=ProbeSettings(\n",
        "        failure_threshold=49,\n",
        "        success_threshold=1,\n",
        "        timeout=299,\n",
        "        period=180,\n",
        "        initial_delay=180,\n",
        "    ),\n",
        "    readiness_probe=ProbeSettings(\n",
        "        failure_threshold=10,\n",
        "        success_threshold=1,\n",
        "        timeout=10,\n",
        "        period=10,\n",
        "        initial_delay=10,\n",
        "    ),\n",
        ")\n",
        "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
        "endpoint.traffic = {deployment_name: 100}\n",
        "workspace_ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1723657353456
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 9. Test the endpoint with sample data\n",
        "\n",
        "We will fetch some sample data from the test dataset and submit to online endpoint for inference. We will then display the scored labels alongside the ground truth labels."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "demo_deployment = workspace_ml_client.online_deployments.get(\n",
        "    name=deployment_name,\n",
        "    endpoint_name=online_endpoint_name,\n",
        ")\n",
        "\n",
        "# Get the details for online endpoint\n",
        "endpoint = workspace_ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "# existing traffic details\n",
        "print(endpoint.traffic)\n",
        "# Get the scoring URI\n",
        "print(endpoint.scoring_uri)\n",
        "print(demo_deployment)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1722983214007
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create request json\n",
        "import base64\n",
        "import json\n",
        "\n",
        "sample_image = os.path.join(dataset_dir, \"images\", \"99.jpg\")\n",
        "\n",
        "\n",
        "def read_image(image_path):\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return f.read()\n",
        "\n",
        "\n",
        "request_json = {\n",
        "    \"input_data\": {\n",
        "        \"columns\": [\"image\"],\n",
        "        \"data\": [base64.encodebytes(read_image(sample_image)).decode(\"utf-8\")],\n",
        "    }\n",
        "}\n",
        "\n",
        "request_file_name = \"sample_request_data.json\"\n",
        "with open(request_file_name, \"w\") as request_file:\n",
        "    json.dump(request_json, request_file)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "resp = workspace_ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=demo_deployment.name,\n",
        "    request_file=request_file_name,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "resp"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualize detections\n",
        "Now that we have scored a test image, we can visualize the prediction for this image."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install matplotlib\n",
        "! pip install seaborn"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "img_np = mpimg.imread(sample_image)\n",
        "img = Image.fromarray(img_np.astype(\"uint8\"), \"RGB\")\n",
        "x, y = img.size\n",
        "conf_threshold = 0.6  # display top objects with confidence score > 0.6\n",
        "\n",
        "# Set a compact figure size\n",
        "fig_width = 12\n",
        "fig_height = 12\n",
        "\n",
        "# Initialize figure and axes\n",
        "fig = plt.figure(figsize=(fig_width, fig_height))\n",
        "gs = fig.add_gridspec(2, 1, height_ratios=[4, 1], hspace=0.2)\n",
        "ax1 = fig.add_subplot(gs[0])\n",
        "ax2 = fig.add_subplot(gs[1])\n",
        "\n",
        "# Display the image with bounding boxes and segmentation maps\n",
        "ax1.imshow(img_np)\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "# Draw bounding boxes and segmentation maps for each detection\n",
        "detections = json.loads(resp)\n",
        "sorted_data = sorted(detections[0][\"boxes\"], key=lambda x: x[\"score\"], reverse=True)\n",
        "sorted_scores = []\n",
        "sorted_colors = []\n",
        "unique_labels = []\n",
        "label_counter = {}\n",
        "\n",
        "# draw box and label for each detection\n",
        "for detect in sorted_data:\n",
        "    label = detect[\"label\"]\n",
        "    box = detect[\"box\"]\n",
        "    conf_score = detect[\"score\"]\n",
        "\n",
        "    if conf_score > conf_threshold:\n",
        "        # Modify labels to make them unique with numbering\n",
        "        if label not in label_counter:\n",
        "            label_counter[label] = 1\n",
        "            unique_labels.append(f\"{label} {label_counter[label]}\")\n",
        "        else:\n",
        "            label_counter[label] += 1\n",
        "            unique_labels.append(f\"{label} {label_counter[label]}\")\n",
        "\n",
        "        current_label = unique_labels[-1]\n",
        "\n",
        "        ymin, xmin, ymax, xmax = (\n",
        "            box[\"topY\"],\n",
        "            box[\"topX\"],\n",
        "            box[\"bottomY\"],\n",
        "            box[\"bottomX\"],\n",
        "        )\n",
        "        topleft_x, topleft_y = x * xmin, y * ymin\n",
        "        width, height = x * (xmax - xmin), y * (ymax - ymin)\n",
        "        print(\n",
        "            f\"{current_label}: [{round(topleft_x, 3)}, {round(topleft_y, 3)}, \"\n",
        "            f\"{round(width, 3)}, {round(height, 3)}], {round(conf_score, 3)}\"\n",
        "        )\n",
        "\n",
        "        color = np.random.rand(3)\n",
        "        rect = patches.Rectangle(\n",
        "            (topleft_x, topleft_y),\n",
        "            width,\n",
        "            height,\n",
        "            linewidth=2,\n",
        "            edgecolor=color,\n",
        "            facecolor=\"none\",\n",
        "        )\n",
        "        ax1.add_patch(rect)\n",
        "        ax1.text(topleft_x, topleft_y - 10, current_label, color=color, fontsize=20)\n",
        "        sorted_scores.append(conf_score)\n",
        "        sorted_colors.append(color)\n",
        "\n",
        "# Set a stylish color palette\n",
        "sns.set_palette(\"pastel\")\n",
        "\n",
        "# Create the bar plot without x-axis and y-axis markings\n",
        "barplot = sns.barplot(x=sorted_scores, y=unique_labels, palette=sorted_colors, ax=ax2)\n",
        "ax2.set_xlabel(\"\")  # Remove x-axis label\n",
        "ax2.set_ylabel(\"\")  # Remove y-axis label\n",
        "ax2.set_title(f\"Top {len(sorted_scores)} Object Scores\", fontsize=12)\n",
        "\n",
        "# Add scores in front of the bars\n",
        "for index, value in enumerate(sorted_scores):\n",
        "    barplot.text(\n",
        "        value + 0.01, index, f\"{value:.2f}\", va=\"center\", color=\"black\", fontsize=10\n",
        "    )\n",
        "\n",
        "# Remove spines and ticks from the bar plot\n",
        "barplot.spines[\"left\"].set_visible(False)\n",
        "barplot.spines[\"top\"].set_visible(False)\n",
        "barplot.spines[\"right\"].set_visible(False)\n",
        "barplot.spines[\"bottom\"].set_visible(False)\n",
        "barplot.tick_params(left=False, top=False, right=False, bottom=False)\n",
        "barplot.xaxis.set_visible(False)  # Remove x-axis\n",
        "barplot.yaxis.grid(False)  # Remove y-axis grid\n",
        "\n",
        "# Set plot background color\n",
        "fig.patch.set_facecolor(\"#F7F7F7\")  # Light gray\n",
        "\n",
        "plt.tight_layout()\n",
        "# fig.savefig(\"plot.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 10. Clean up resources - delete the online endpoint\n",
        "Don't forget to delete the online endpoint, else you will leave the billing meter running for the compute used by the endpoint."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "workspace_ml_client.online_endpoints.begin_delete(name=online_endpoint_name).wait()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}